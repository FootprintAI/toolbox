#!/usr/bin/env python3

"""
Semgrep Static Code Analysis Scanner
A Python wrapper for running Semgrep security scans using Docker
"""

import argparse
import json
import logging
import subprocess
import sys
import tarfile
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional


class SemgrepScanner:
    """Docker-based Semgrep static code analysis scanner"""
    
    def __init__(self, script_dir: Path = None):
        if script_dir:
            self.script_dir = script_dir
            self.log_dir = self.script_dir / "logs"
            self.reports_dir = self.script_dir / "security-reports"
        else:
            # Use current working directory when script_dir not provided
            self.script_dir = Path.cwd()
            self.log_dir = self.script_dir / "logs"
            self.reports_dir = self.script_dir / "security-reports"
        self.semgrep_image = "returntocorp/semgrep:latest"
        
        # Create directories
        self.log_dir.mkdir(exist_ok=True)
        self.reports_dir.mkdir(exist_ok=True)
        
        # Setup logging
        self._setup_logging()
        
    def _setup_logging(self):
        """Configure logging to file and console"""
        log_file = self.log_dir / "semgrep-scan.log"
        
        logging.basicConfig(
            level=logging.INFO,
            format='[%(asctime)s] %(levelname)s: %(message)s',
            handlers=[
                logging.FileHandler(log_file),
                logging.StreamHandler(sys.stdout)
            ]
        )
        self.logger = logging.getLogger(__name__)
        
    def _run_docker_command(self, cmd: List[str]) -> subprocess.CompletedProcess:
        """Run Docker command with error handling"""
        try:
            self.logger.info(f"Running: docker {' '.join(cmd)}")
            result = subprocess.run(
                ["docker"] + cmd,
                capture_output=True,
                text=True,
                check=True
            )
            return result
        except subprocess.CalledProcessError as e:
            self.logger.error(f"Docker command failed: {e}")
            self.logger.error(f"stderr: {e.stderr}")
            raise
            
    def _check_docker(self) -> bool:
        """Check if Docker is available"""
        try:
            subprocess.run(["docker", "--version"], capture_output=True, check=True)
            return True
        except (subprocess.CalledProcessError, FileNotFoundError):
            return False
            
    def pull_semgrep_image(self):
        """Pull latest Semgrep Docker image"""
        self.logger.info(f"Pulling {self.semgrep_image}...")
        self._run_docker_command(["pull", self.semgrep_image])
        
    def scan_security(self, 
                     target_path: Path,
                     severity: Optional[str] = None,
                     rules: str = "auto") -> Dict[str, Path]:
        """Run security-focused Semgrep scan"""
        timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
        target_name = target_path.name if target_path.name else "repo"
        
        output_files = {}
        
        # JSON report
        json_file = self.reports_dir / f"semgrep-security-{target_name}-{timestamp}.json"
        cmd = [
            "run", "--rm",
            "-v", f"{target_path}:/src",
            "-v", f"{self.reports_dir}:/reports",
            self.semgrep_image,
            "semgrep",
            "--config", rules,
            "--json",
            "--output", f"/reports/{json_file.name}",
            "/src"
        ]
        
        if severity:
            cmd.extend(["--severity", severity])
            
        self.logger.info(f"Running security scan on: {target_path}")
        self._run_docker_command(cmd)
        output_files["json"] = json_file
        
        # SARIF format for CI/CD integration
        sarif_file = json_file.with_suffix(".sarif")
        cmd_sarif = [
            "run", "--rm",
            "-v", f"{target_path}:/src",
            "-v", f"{self.reports_dir}:/reports",
            self.semgrep_image,
            "semgrep",
            "--config", rules,
            "--sarif",
            "--output", f"/reports/{sarif_file.name}",
            "/src"
        ]
        
        if severity:
            cmd_sarif.extend(["--severity", severity])
            
        self._run_docker_command(cmd_sarif)
        output_files["sarif"] = sarif_file
        
        # Text report for human reading
        text_file = json_file.with_suffix(".txt")
        cmd_text = [
            "run", "--rm",
            "-v", f"{target_path}:/src",
            "-v", f"{self.reports_dir}:/reports",
            self.semgrep_image,
            "semgrep",
            "--config", rules,
            "--text",
            "--output", f"/reports/{text_file.name}",
            "/src"
        ]
        
        if severity:
            cmd_text.extend(["--severity", severity])
            
        self._run_docker_command(cmd_text)
        output_files["text"] = text_file
        
        self.logger.info(f"Security scan completed: {json_file}")
        return output_files
        
    def scan_custom_rules(self, 
                         target_path: Path,
                         config_file: Path,
                         severity: Optional[str] = None) -> Dict[str, Path]:
        """Run Semgrep scan with custom rules"""
        timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
        target_name = target_path.name if target_path.name else "repo"
        
        output_files = {}
        
        # JSON report
        json_file = self.reports_dir / f"semgrep-custom-{target_name}-{timestamp}.json"
        cmd = [
            "run", "--rm",
            "-v", f"{target_path}:/src",
            "-v", f"{config_file}:/config.yml",
            "-v", f"{self.reports_dir}:/reports",
            self.semgrep_image,
            "semgrep",
            "--config", "/config.yml",
            "--json",
            "--output", f"/reports/{json_file.name}",
            "/src"
        ]
        
        if severity:
            cmd.extend(["--severity", severity])
            
        self.logger.info(f"Running custom rules scan on: {target_path}")
        self._run_docker_command(cmd)
        output_files["json"] = json_file
        
        return output_files
        
    def scan_language_specific(self, 
                              target_path: Path,
                              language: str,
                              severity: Optional[str] = None) -> Dict[str, Path]:
        """Run language-specific security scans"""
        timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
        target_name = target_path.name if target_path.name else "repo"
        
        # Language to ruleset mapping
        language_rules = {
            "go": "p/golang",
            "javascript": "p/javascript", 
            "typescript": "p/typescript",
            "python": "p/python",
            "docker": "p/docker",
            "security": "p/security-audit"
        }
        
        if language not in language_rules:
            raise ValueError(f"Unsupported language: {language}. Supported: {list(language_rules.keys())}")
            
        rules = language_rules[language]
        output_files = {}
        
        # JSON report
        json_file = self.reports_dir / f"semgrep-{language}-{target_name}-{timestamp}.json"
        cmd = [
            "run", "--rm",
            "-v", f"{target_path}:/src",
            "-v", f"{self.reports_dir}:/reports",
            self.semgrep_image,
            "semgrep",
            "--config", rules,
            "--json",
            "--output", f"/reports/{json_file.name}",
            "/src"
        ]
        
        if severity:
            cmd.extend(["--severity", severity])
            
        self.logger.info(f"Running {language} scan on: {target_path}")
        self._run_docker_command(cmd)
        output_files["json"] = json_file
        
        # Text report
        text_file = json_file.with_suffix(".txt")
        cmd_text = [
            "run", "--rm",
            "-v", f"{target_path}:/src",
            "-v", f"{self.reports_dir}:/reports",
            self.semgrep_image,
            "semgrep",
            "--config", rules,
            "--text",
            "--output", f"/reports/{text_file.name}",
            "/src"
        ]
        
        if severity:
            cmd_text.extend(["--severity", severity])
            
        self._run_docker_command(cmd_text)
        output_files["text"] = text_file
        
        self.logger.info(f"{language.title()} scan completed: {json_file}")
        return output_files
        
    def comprehensive_scan(self, 
                          target_path: Path,
                          severity: str = "ERROR") -> Dict[str, Dict[str, Path]]:
        """Run comprehensive scan for Go/Next.js/Python stack"""
        self.logger.info(f"Running comprehensive scan on: {target_path}")
        
        results = {}
        
        # Security audit scan
        try:
            results["security"] = self.scan_security(target_path, severity, "p/security-audit")
        except Exception as e:
            self.logger.warning(f"Security scan failed: {e}")
            
        # Language-specific scans
        languages = ["go", "javascript", "typescript", "python", "docker"]
        
        for lang in languages:
            try:
                results[lang] = self.scan_language_specific(target_path, lang, severity)
                self.logger.info(f"{lang.title()} scan completed")
            except Exception as e:
                self.logger.warning(f"{lang.title()} scan failed: {e}")
                
        self.logger.info(f"Comprehensive scan completed. {len(results)} scans run.")
        return results
        
    def generate_summary(self, report_file: Path) -> Dict:
        """Generate summary from JSON report"""
        try:
            with open(report_file) as f:
                data = json.load(f)
            
            summary = {
                "total_findings": len(data.get("results", [])),
                "by_severity": {"ERROR": 0, "WARNING": 0, "INFO": 0},
                "by_category": {},
                "scan_target": str(report_file.parent.parent)
            }
            
            for finding in data.get("results", []):
                # Count by severity
                severity = finding.get("extra", {}).get("severity", "INFO")
                if severity in summary["by_severity"]:
                    summary["by_severity"][severity] += 1
                    
                # Count by category/rule
                rule_id = finding.get("check_id", "unknown")
                category = rule_id.split(".")[0] if "." in rule_id else "other"
                summary["by_category"][category] = summary["by_category"].get(category, 0) + 1
                    
            return summary
        except Exception as e:
            self.logger.error(f"Error generating summary: {e}")
            return {}
    
    def _get_repo_name(self, target_path: Path) -> str:
        """Extract repository name from target path"""
        if target_path.is_dir():
            return target_path.name
        else:
            return target_path.parent.name
    
    def create_report_archive(self, target_path: Path, report_files: List[Path]) -> Path:
        """Create tar.gz archive of all report files"""
        repo_name = self._get_repo_name(target_path)
        timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
        archive_name = f"{repo_name}_{timestamp}.tar.gz"
        archive_path = self.reports_dir / archive_name
        
        try:
            with tarfile.open(archive_path, "w:gz") as tar:
                for report_file in report_files:
                    if report_file.exists():
                        # Add file with just the filename (not full path) in archive
                        tar.add(report_file, arcname=report_file.name)
                        self.logger.info(f"Added {report_file.name} to archive")
            
            self.logger.info(f"Created report archive: {archive_path}")
            return archive_path
        except Exception as e:
            self.logger.error(f"Error creating archive: {e}")
            raise


def main():
    """Main CLI interface"""
    parser = argparse.ArgumentParser(
        description="Semgrep static code analysis scanner",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  %(prog)s security /path/to/code --severity ERROR
  %(prog)s language --lang go /path/to/go-project
  %(prog)s comprehensive /path/to/full-stack-app
  %(prog)s custom /path/to/code --config custom-rules.yml
        """
    )
    
    subparsers = parser.add_subparsers(dest="command", help="Available commands")
    
    # Security scan
    security_parser = subparsers.add_parser("security", help="Run security-focused scan")
    security_parser.add_argument("path", help="Path to scan")
    security_parser.add_argument("-s", "--severity", help="Minimum severity (INFO, WARNING, ERROR)")
    security_parser.add_argument("-r", "--rules", default="p/security-audit", help="Rule set to use")
    
    # Language-specific scan
    lang_parser = subparsers.add_parser("language", help="Run language-specific scan")
    lang_parser.add_argument("path", help="Path to scan")
    lang_parser.add_argument("-l", "--lang", required=True, 
                           choices=["go", "javascript", "typescript", "python", "docker"],
                           help="Programming language")
    lang_parser.add_argument("-s", "--severity", help="Minimum severity (INFO, WARNING, ERROR)")
    
    # Comprehensive scan
    comp_parser = subparsers.add_parser("comprehensive", help="Run comprehensive multi-language scan")
    comp_parser.add_argument("path", help="Path to scan")
    comp_parser.add_argument("-s", "--severity", default="ERROR", help="Minimum severity")
    
    # Custom rules scan
    custom_parser = subparsers.add_parser("custom", help="Run scan with custom rules")
    custom_parser.add_argument("path", help="Path to scan")
    custom_parser.add_argument("-c", "--config", required=True, help="Custom rules config file")
    custom_parser.add_argument("-s", "--severity", help="Minimum severity (INFO, WARNING, ERROR)")
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return 1
        
    # Initialize scanner
    scanner = SemgrepScanner()
    
    # Check Docker availability
    if not scanner._check_docker():
        print("Error: Docker is not installed or not available")
        return 1
        
    # Pull Semgrep image
    scanner.pull_semgrep_image()
    
    try:
        target_path = Path(args.path).resolve()
        
        if args.command == "security":
            results = scanner.scan_security(target_path, args.severity, args.rules)
            
        elif args.command == "language":
            results = scanner.scan_language_specific(target_path, args.lang, args.severity)
            
        elif args.command == "comprehensive":
            results = scanner.comprehensive_scan(target_path, args.severity)
            
        elif args.command == "custom":
            config_path = Path(args.config).resolve()
            results = scanner.scan_custom_rules(target_path, config_path, args.severity)
            
        # Create archive and print summary
        if args.command == "comprehensive":
            # Collect all report files from comprehensive scan
            all_reports = []
            for scan_type, scan_results in results.items():
                if isinstance(scan_results, dict):
                    all_reports.extend(scan_results.values())
            
            if all_reports:
                archive_path = scanner.create_report_archive(target_path, all_reports)
                print(f"\nComprehensive scan completed with {len(results)} scans")
                print(f"Archive created: {archive_path}")
        else:
            # Single scan - create archive and print summary
            report_files = list(results.values()) if isinstance(results, dict) else []
            if report_files:
                archive_path = scanner.create_report_archive(target_path, report_files)
                print(f"Archive created: {archive_path}")
            
            if "json" in results:
                summary = scanner.generate_summary(results["json"])
                if summary:
                    print(f"\nScan Summary:")
                    print(f"Target: {summary['scan_target']}")
                    print(f"Total findings: {summary['total_findings']}")
                    for sev, count in summary['by_severity'].items():
                        if count > 0:
                            print(f"  {sev}: {count}")
                        
        print(f"\nReports saved to: {scanner.reports_dir}")
        return 0
        
    except Exception as e:
        print(f"Error: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())